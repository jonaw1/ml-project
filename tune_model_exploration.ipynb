{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standardized vs. non-standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from data/preprocessed.csv\n",
      "Split the data into training and testing sets (80%/20%)\n",
      "Standardized the data\n",
      "Non-standardized score: 0.9121564406849627\n",
      "Non-standardized ME: 19221.480517430282\n",
      "Standardized score: 0.9044382420997802\n",
      "Standardized ME: 20048.1331754706\n"
     ]
    }
   ],
   "source": [
    "from src.train_model import split_data, standardize_data\n",
    "from src.preprocessing import load_data\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PREPROCESSED_FILE_PATH = os.getenv('PREPROCESSED_DATA_PATH').replace('/', os.sep)\n",
    "TARGET_COLUMN = os.getenv('TARGET_COLUMN')\n",
    "BEST_PARAMS_PATH = os.getenv('BEST_PARAMS_PATH').replace('/', os.sep)\n",
    "\n",
    "data = load_data(PREPROCESSED_FILE_PATH)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(data, TARGET_COLUMN)\n",
    "\n",
    "base_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "base_model.fit(X_train, y_train)\n",
    "non_standardized_score = base_model.score(X_test, y_test)\n",
    "non_standardized_me = mean_squared_error(y_test, base_model.predict(X_test), squared=False)\n",
    "\n",
    "X_train_std, X_test_std = standardize_data(X_train, X_test)\n",
    "base_model.fit(X_train_std, y_train)\n",
    "standardized_score = base_model.score(X_test_std, y_test)\n",
    "standardized_me = mean_squared_error(y_test, base_model.predict(X_test_std), squared=False)\n",
    "\n",
    "print(f'Non-standardized score: {non_standardized_score}')\n",
    "print(f'Non-standardized ME: {non_standardized_me}')\n",
    "print(f'Standardized score: {standardized_score}')\n",
    "print(f'Standardized ME: {standardized_me}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => Keeping the data non-standardized seeems to yield a better performance for random forest regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Random Search with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Best random score: 0.9116627070456951\n",
      "Best random ME: 19275.422967282422\n",
      "Base model score: 0.9121564406849627\n",
      "Base model ME: 19221.480517430282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "random_grid = {\n",
    "  'n_estimators': randint(50, 500),\n",
    "  'max_features': ['sqrt', 'log2', None, 0.1, 0.5],\n",
    "  'max_depth': randint(5, 30),\n",
    "  'min_samples_split': randint(2, 10),\n",
    "  'min_samples_leaf': randint(2, 10),\n",
    "  'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "  random_state=42,\n",
    "  estimator=model,\n",
    "  param_distributions=random_grid,\n",
    "  scoring='neg_mean_absolute_error',\n",
    "  n_iter=100,\n",
    "  cv=3,\n",
    "  verbose=1,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "best_random.fit(X_train, y_train)\n",
    "best_random_score = best_random.score(X_test, y_test)\n",
    "best_random_me = mean_squared_error(y_test, best_random.predict(X_test), squared=False)\n",
    "\n",
    "print(f'Best random score: {best_random_score}')\n",
    "print(f'Best random ME: {best_random_me}')\n",
    "print(f'Base model score: {non_standardized_score}')\n",
    "print(f'Base model ME: {non_standardized_me}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => Best estimator after random search yields a small improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Grid Search with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'max_depth': 16, 'max_features': 0.1, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 242}\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Best grid score: 0.9204163287279854\n",
      "Best grid ME: 18295.482115763014\n",
      "Base model score: 0.9121564406849627\n",
      "Base model ME: 19221.480517430282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "  'n_estimators': [180, 220, 260, 300],\n",
    "  'max_features': [0.1, 0.2, 0.3],\n",
    "  'max_depth': [13, 16, 19],\n",
    "  'min_samples_split': [5, 6, 7],\n",
    "  'min_samples_leaf': [1, 2, 3],\n",
    "  'bootstrap': [False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=model,\n",
    "  param_grid=param_grid,\n",
    "  scoring='neg_mean_absolute_error',\n",
    "  cv=3,\n",
    "  verbose=1,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "best_grid_score = best_grid.score(X_test, y_test)\n",
    "best_grid_me = mean_squared_error(y_test, best_grid.predict(X_test), squared=False)\n",
    "\n",
    "print(f'Best grid score: {best_grid_score}')\n",
    "print(f'Best grid ME: {best_grid_me}')\n",
    "print(f'Base model score: {non_standardized_score}')\n",
    "print(f'Base model ME: {non_standardized_me}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.dump(grid_search.best_params_, open(BEST_PARAMS_PATH, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => Achieved an improvement of ME: -926â‚¬ and R2: +0.825%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
